<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<!-- saved from url=(0075)http://blog.malde.org/posts/optimization-week-making-haskell-go-faster.html -->
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        
<meta name="google-site-verification" content="I7I5u_ALHnW8e0J6jrgkChquEl587Bdh7iTyRvZSXoU">
        <title>Optimization week: making Haskell go faster</title>
	<link rel="shortcut icon" href="http://blog.malde.org/images/favicon.jpg">
        <link rel="stylesheet" type="text/css" href="./Optimization week  making Haskell go faster_files/default.css">
        <link rel="alternate" type="application/rss+xml" title="untitled" href="http://blog.malde.org/rss.xml">
	<script type="text/javascript" async="" src="https://apis.google.com/js/plusone.js"></script><script type="text/javascript">
	  (function() {
	    var po = document.createElement('script'); po.type = 'text/javascript'; po.async = true;
	    po.src = 'https://apis.google.com/js/plusone.js';
	    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
 	 })();
	</script>
    <script type="text/javascript" async="" src="./Optimization week  making Haskell go faster_files/embed.js"></script></head>
    <body>
      <div id="header">
	<span id="logo">
	  <img src="./Optimization week  making Haskell go faster_files/lambda_skull.png" alt="Expanding lambda skull" title="Warning: Functional programming can expand your
	       mind!">
	</span>
        <span id="blogname">Under deconstruction</span>
	<span id="icons">
	  <a href="http://blog.malde.org/rss.xml"><img src="./Optimization week  making Haskell go faster_files/rss48.png" alt="RSS" title="Subscribe to RSS feed"></a>
	</span>
        <!-- p>Optimization week: making Haskell go faster</p -->
        <div id="navbar">
          <a href="http://blog.malde.org/index.html">Main page</a>
          <a href="http://blog.malde.org/about.html">About</a>	    
          <a href="http://blog.malde.org/posts.html">All posts</a>
        </div>
      </div>
      <div id="main">        
        <h1>Optimization week: making Haskell go faster</h1>

<p class="noindent">by <em>Ketil Malde</em>; <strong>May 18, 2008</strong></p>

<p>It seems to be optimization week on the haskell café mailing list. Inspired by a combination of Don Stewart’s <a href="http://cgi.cse.unsw.edu.au/~dons/blog/2008/05">blog post</a> about how to optimize for speed and the sorry performance of my <a href="http://malde.org/~ketil/biohaskell/xml2x">xml2x</a> program, I thought this would be good time to see if things could be improved. In its current state, xml2x takes a few hours to process a few days worth of BLASTX output, so it’s far from critical, but faster is always better, and reading Don’s post, the intermediate output from the compiler, a.k.a. <em>ghc core</em> didn’t really look so scary.</p>
<h2 id="profiling-with-haskell">Profiling with Haskell</h2>
<p>First we need to identify the actual bottlenecks, using GHC’s profiling options. This means compiling the program with <code>-prof -auto-all</code>, and the <code>Makefile</code> shipped with xml2x already has a target for this. (I could probably do it with Cabal as well, but I never bothered to find out. Lazy me.) A <a href="http://malde.org/~ketil/biohaskell/biolib">bioinformatics library</a> is that its Cabal file contains this line:</p>
<pre><code>ghc-options:         -Wall -O2 -fexcess-precision -funbox-strict-fields -auto-all</code></pre>
<p>The final <code>auto-all</code> ensures that when the library gets compiled with profiling support, cost centres will be assigned to its internal functions too, thus the profiling run will reveal where time is being spent in more detail. This practice is probably frowned upon by people who are into that kind of thing, but here it is crucial, as the profile reveals this:</p>
<pre><code>Fri May 16 18:28 2008 Time and Allocation Profiling Report  (Final)

xml2x.p +RTS -p -sxml2x.p2.stats -RTS -v -C --reg --go-def=GO.terms_and_ids
    --anno=gene_association.goa_uniprot small.xml -o small3.csv

total time  =     4073.12 secs   (203656 ticks @ 20 ms)
total alloc = 1082,832,292,360 bytes  (excludes profiling overheads)

COST CENTRE                    MODULE               %time %alloc

mkAnn                          Bio.Sequence.GOA        60.8   56.2
readXML                        Bio.Alignment.BlastXML  27.4   38.4
hsp2match                      Bio.Alignment.BlastXML   3.1    1.7
readGOA                        Bio.Sequence.GOA         1.9    0.4
hit2hit                        Bio.Alignment.BlastXML   1.6    1.8
protTerms                      Main                     1.6    0.0
sequence'                      Bio.Util                 1.1    0.2&lt;/pre&gt;</code></pre>
<p>In short, the function named mkAnn consumes almost two thirds of the time here, and is an obvious target for closer inspection. The function looks like this:</p>
<pre><code>data Annotation = Ann !UniProtAcc !GoTerm !EvidenceCode deriving (Show)
newtype GoTerm = GO Int deriving (Eq,Ord)
type UniProtAcc = ByteString

mkAnn :: ByteString -&gt; Annotation
mkAnn = pick . B.words
    where pick (_db:up:rest) = pick' up $ findGo rest
        pick' up' (go:_:ev:_) = Ann (copy up') (read $ unpack go) (read $ unpack ev)
        findGo = dropWhile (not . B.isPrefixOf (pack "GO:"))</code></pre>
<p>This is a slightly clunky way of extracting a bit of information from a line of text; the text in question is <a href="http://www.geneontology.org/">GOA</a>, a mapping between proteins and standard Gene Onthology terms. It’s a text file with about 20 million lines, so we use lazy bytestrings to deal with it. Each line is broken into words, the second word (“up”) is the protein name. Then a variable number of words later, the GO term itself appears, and the final item we want is the third word after the GO term. Note the <code>copy</code>, ensuring that we don’t keep around a large part of the input file.</p>
<p>So what’s wrong here? Asking in the café, Don suggested that unpacking bytestrings is a less than recommendable practice. Still, I find it is a useful idiom, and the <code>read $ unpack s</code> should garbage-collect the characters as soon as they are consumed. Ideally, the string should be deforested or fused away. I happily agree that this is a lazy programmer’s approach and not optimal - but on the other hand, it shouldn’t be <em>that</em> costly?</p>
<h2 id="ghc-core-to-the-rescue---not.">GHC core to the rescue - not.</h2>
<p>This is the stage where I looked at GHC core. I guess it’s one of those things that looks easy when professionals do it, but when you get home and try it on your own, you just have no idea. The three-line function above resulted in four pages of cryptic core output. Call me lazy and ignorant, but I decided to take just one more little peek at the source first.</p>
<p>Let’s check out those read-unpack constructs. The read instance for <code>GoTerm</code> checks that the string starts with “GO:”, and then reads an <code>Int</code>. The second reads an <a href="http://www.geneontology.org/GO.evidence.shtml">EvidenceCode</a>, and since these are defined as short abbreviations in all upper case, I just wrote a data type with corresponding nullary constructors, and derived <code>Read</code> for it.</p>
<pre><code>data EvidenceCode = IC  -- Inferred by Curator
      | IDA -- Inferred from Direct Assay
      | IEA -- Inferred from Electronic Annotation
      | IEP -- Inferred from Expression Pattern
      | IGC -- Inferred from Genomic Context
      | IGI -- Inferred from Genetic Interaction
      | IMP -- Inferred from Mutant Phenotype
      | IPI -- Inferred from Physical Interaction
      | ISS -- Inferred from Sequence or Structural Similarity
      | NAS -- Non-traceable Author Statement
      | ND  -- No biological Data available
      | RCA -- inferred from Reviewed Computational Analysis
      | TAS -- Traceable Author Statement
      | NR  -- Not Recorded
   deriving (Read,Show,Eq)&lt;/pre&gt;</code></pre>
<p>Maybe this wasn’t such a good idea after all? Let’s try with custom, bytestring-based parsers for EvidenceCode and GoTerm:</p>
<pre><code>getEC :: ByteString -&gt; EvidenceCode
getEC s = case B.uncons s of
        Just ('I',s') -&gt; case B.uncons s' of
                           Just ('C',_) -&gt; IC
                           Just ('D',_) -&gt; IDA
                           Just ('E',s'') -&gt; case B.head s'' of 'A' -&gt; IEA
                                                                'P' -&gt; IEP
                                                                _ -&gt; e 1
                           Just ('G',s'') -&gt; case B.head s'' of 'C' -&gt;; IGC
                                                                'I' -&gt; IGI
                                                                _ -&gt; e 2
                           Just ('M',_) -&gt; IMP
                           Just ('P',_) -&gt; IPI
                           Just ('S',_) -&gt; ISS
                           _ -&gt; e 3
        Just ('N',s') -&gt; case B.head s' of 'A' -&gt; NAS
                                           'D' -&gt; ND
                                           'R' -&gt; NR
                                           _ -&gt; e 4
        Just ('R',_) -&gt; RCA
        Just ('T',_) -&gt; TAS
        _ -&gt; e 5
where e :: Int -&gt; a
      e n = error ("Illegal GO evidence code ("++show n++"): "++unpack s)

getGo :: ByteString -&gt; GoTerm
getGo bs = GO $ fst $ maybe e id (B.readInt $ B.drop 3 bs)
    where e = error ("Unable to parse GO term"++unpack bs)&lt;/pre&gt;</code></pre>
<p>Time to re-run with profiling:</p>
<pre><code>Sat May 17 19:25 2008 Time and Allocation Profiling Report  (Final)

xml2x.p +RTS -sxml2x.2pp.stats -p -RTS -v -C --reg --go-def=GO.terms_and_ids
--anno=gene_association.goa_uniprot small.xml -o small5p.csv

total time  =     2022.36 secs   (101118 ticks @ 20 ms)
total alloc = 622,807,651,828 bytes  (excludes profiling overheads)

COST CENTRE                    MODULE               %time %alloc

readXML                        Bio.Alignment.BlastXML  48.6   66.7
mkAnn                          Bio.Sequence.GOA        29.8   23.6
hsp2match                      Bio.Alignment.BlastXML   5.2    3.0
readGOA                        Bio.Sequence.GOA         3.6    0.7
hit2hit                        Bio.Alignment.BlastXML   3.2    3.0
protTerms                      Main                     3.1    0.0
sequence'                      Bio.Util                 2.1    0.4
countIO                        Bio.Util                 1.4    0.6
getFrom                        Bio.Alignment.BlastXML   1.1    0.7&lt;/pre&gt;</code></pre>
<p>We see that <code>mkAnn</code> has fallen way behind the XML parsing in time consumption, and until Neil gets around to do a bytestring version of his otherwise excellent <a href="http://www-users.cs.york.ac.uk/~ndm/tagsoup/">tagsoup</a> library, there isn’t all that much left to do. Total time has been cut in half, from over an hour to 35 minutes or so. There’s still 30% of the run time to be shaved even more closely, perhaps you can suggest the remaining culprit? My guess would be the <code>findGo</code> function. How should it be rewritten?</p>
<h2 id="lessons-learned">Lessons learned</h2>
<p>Profiling is nice to pinpoint the hotspots. Bytestrings is <em>the</em> way to go for fast code. GHC generates crappy derived parsers for data types, perhaps especially so for data types with many constructors. Writing manual parsers is tedious, but a bit of tedium can go a long way.</p>
<p>Unfortunatly, I am still not entirely happy with <code>xml2x</code>. The profiling numbers lie, as they don’t – I believe – include GC time. This particular program uses an inordinate amount of time collecting garbage. I <em>suspect</em> it is because I store GO terms as 16 bit integers in unboxed arrays in an insufficiently strict Data.Map, but I will have to investigate this closer.</p>
<p>But not today.</p>

<div id="disqus_thread"><iframe id="dsq-2" data-disqus-uid="2" allowtransparency="true" frameborder="0" tabindex="0" title="Disqus" width="100%" src="./Optimization week  making Haskell go faster_files/saved_resource.htm" scrolling="no" horizontalscrolling="no" verticalscrolling="no" style="width: 100% !important; border: none !important; overflow: hidden !important; height: 603px !important;"></iframe></div>
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'ketil'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the &lt;a href="http://disqus.com/?ref_noscript"&gt;comments powered by Disqus.&lt;/a&gt;</noscript>
    <a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>


	<div id="comments">Feedback? Please email <a href="mailto:ketil@malde.org">ketil@malde.org</a>.</div>
	<div id="footer">
	  <g:plusone annotation="inline"></g:plusone>
	  <a href="http://www.reddit.com/submit" onclick="window.location = &#39;http://www.reddit.com/submit?url=&#39; + encodeURIComponent(window.location); return false"> <img src="./Optimization week  making Haskell go faster_files/spreddit7.gif" alt="submit to reddit" border="0"></a>
	</div>
      </div>
    

</body></html>